{"transformers.tokenization_xlnet.XLNetTokenizer.__init__": ["transformers.tokenization_utils.PreTrainedTokenizer.__init__", "<builtin>.super", "sentencepiece.SentencePieceProcessor"], "transformers.modeling_xlnet.XLNetModel.__init__": ["transformers.modeling_utils.PreTrainedModel.__init__", "<builtin>.super", "torch.nn.Embedding", "torch.nn.Parameter", "torch.FloatTensor", "torch.nn.ModuleList", "transformers.modeling_xlnet.XLNetLayer.__init__", "<builtin>.range", "torch.nn.Dropout", "transformers.modeling_utils.PreTrainedModel.init_weights"], "transformers.modeling_utils.SequenceSummary.__init__": ["<builtin>.super", "<builtin>.getattr", "transformers.modeling_utils.Identity.__init__", "torch.nn.Identity", "<builtin>.hasattr", "torch.nn.Linear", "transformers.activations.get_activation", "torch.nn.Dropout"], "transformers.modeling_bert.BertModel.__init__": ["transformers.modeling_utils.PreTrainedModel.__init__", "<builtin>.super", "transformers.modeling_bert.BertEmbeddings.__init__", "transformers.modeling_bert.BertEncoder.__init__", "transformers.modeling_bert.BertPooler.__init__", "transformers.modeling_utils.PreTrainedModel.init_weights"], "transformers.tokenization_bert.BertTokenizer.__init__": ["transformers.tokenization_utils.PreTrainedTokenizer.__init__", "<builtin>.super", "os.path.isfile", "<builtin>.ValueError", "transformers.tokenization_bert.load_vocab", "collections.OrderedDict", "transformers.tokenization_bert.BasicTokenizer.__init__", "transformers.tokenization_bert.WordpieceTokenizer.__init__"], "transformers.tokenization_utils.PreTrainedTokenizer.__init__": ["transformers.tokenization_utils.SpecialTokensMixin.__init__", "<builtin>.super", "<builtin>.set"], "transformers.modeling_utils.PreTrainedModel.__init__": ["<builtin>.super", "<builtin>.isinstance", "<builtin>.ValueError"], "transformers.modeling_xlnet.XLNetLayer.__init__": ["<builtin>.super", "transformers.modeling_xlnet.XLNetRelativeAttention.__init__", "transformers.modeling_xlnet.XLNetFeedForward.__init__", "torch.nn.Dropout"], "transformers.modeling_utils.PreTrainedModel.init_weights": ["transformers.modeling_utils.PreTrainedModel.prune_heads", "transformers.modeling_utils.PreTrainedModel.tie_weights"], "transformers.modeling_utils.Identity.__init__": ["<builtin>.super"], "transformers.activations.get_activation": ["<builtin>.KeyError", "<builtin>.list"], "transformers.modeling_bert.BertEmbeddings.__init__": ["<builtin>.super", "torch.nn.Embedding", "torch.nn.Dropout"], "transformers.modeling_bert.BertEncoder.__init__": ["<builtin>.super", "torch.nn.ModuleList", "transformers.modeling_bert.BertLayer.__init__", "<builtin>.range"], "transformers.modeling_bert.BertPooler.__init__": ["<builtin>.super", "torch.nn.Linear", "torch.nn.Tanh"], "transformers.tokenization_bert.load_vocab": ["collections.OrderedDict", "<builtin>.open", "<builtin>.enumerate"], "transformers.tokenization_utils.SpecialTokensMixin.__init__": ["<builtin>.isinstance", "<builtin>.all", "<builtin>.setattr", "<builtin>.str", "<builtin>.TypeError", "<builtin>.type"], "transformers.modeling_xlnet.XLNetRelativeAttention.__init__": ["<builtin>.super", "<builtin>.ValueError", "torch.nn.Parameter", "torch.FloatTensor", "torch.nn.Dropout"], "transformers.modeling_xlnet.XLNetFeedForward.__init__": ["<builtin>.super", "torch.nn.Linear", "torch.nn.Dropout", "<builtin>.isinstance"], "transformers.modeling_utils.PreTrainedModel.prune_heads": ["<builtin>.list", "<builtin>.set"], "transformers.modeling_utils.PreTrainedModel.tie_weights": ["transformers.modeling_utils.PreTrainedModel.get_output_embeddings", "transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights", "transformers.modeling_utils.PreTrainedModel.get_input_embeddings"], "transformers.modeling_bert.BertLayer.__init__": ["<builtin>.super", "transformers.modeling_bert.BertAttention.__init__", "transformers.modeling_bert.BertIntermediate.__init__", "transformers.modeling_bert.BertOutput.__init__"], "transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights": ["torch.nn.Parameter", "<builtin>.getattr", "torch.nn.functional.pad", "<builtin>.hasattr"], "transformers.modeling_utils.PreTrainedModel.get_input_embeddings": ["<builtin>.getattr"], "transformers.modeling_bert.BertAttention.__init__": ["<builtin>.super", "transformers.modeling_bert.BertSelfAttention.__init__", "transformers.modeling_bert.BertSelfOutput.__init__", "<builtin>.set"], "transformers.modeling_bert.BertIntermediate.__init__": ["<builtin>.super", "torch.nn.Linear", "<builtin>.isinstance"], "transformers.modeling_bert.BertOutput.__init__": ["<builtin>.super", "torch.nn.Linear", "torch.nn.Dropout"], "transformers.modeling_bert.BertSelfAttention.__init__": ["<builtin>.super", "<builtin>.ValueError", "<builtin>.hasattr", "<builtin>.int", "torch.nn.Linear", "torch.nn.Dropout"], "transformers.modeling_bert.BertSelfOutput.__init__": ["<builtin>.super", "torch.nn.Linear", "torch.nn.Dropout"]}