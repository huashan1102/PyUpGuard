{"transformers.optimization.AdamW.__init__": ["warnings.warn", "transformers.utils.versions.require_version", "<builtin>.ValueError", "<builtin>.dict", "torch.optim.Optimizer.__init__", "<builtin>.super"], "transformers.models.distilbert.modeling_distilbert.DistilBertModel.__init__": ["transformers.modeling_utils.PreTrainedModel.__init__", "<builtin>.super", "transformers.models.distilbert.modeling_distilbert.Embeddings.__init__", "transformers.models.distilbert.modeling_distilbert.Transformer.__init__", "transformers.modeling_utils.PreTrainedModel.post_init"], "transformers.utils.dummy_pt_objects.DistilBertModel.__init__": ["transformers.file_utils.requires_backends"], "transformers.models.albert.modeling_albert.AlbertModel.__init__": ["transformers.modeling_utils.PreTrainedModel.__init__", "<builtin>.super", "transformers.models.albert.modeling_albert.AlbertEmbeddings.__init__", "transformers.models.albert.modeling_albert.AlbertTransformer.__init__", "torch.nn.Linear", "torch.nn.Tanh", "transformers.modeling_utils.PreTrainedModel.post_init"], "transformers.utils.dummy_pt_objects.AlbertModel.__init__": ["transformers.file_utils.requires_backends"], "transformers.models.bert.modeling_bert.BertModel.__init__": ["transformers.modeling_utils.PreTrainedModel.__init__", "<builtin>.super", "transformers.models.bert.modeling_bert.BertEmbeddings.__init__", "transformers.models.bert.modeling_bert.BertEncoder.__init__", "transformers.models.bert.modeling_bert.BertPooler.__init__", "transformers.modeling_utils.PreTrainedModel.post_init"], "transformers.utils.dummy_pt_objects.BertModel.__init__": ["transformers.file_utils.requires_backends"], "transformers.optimization.get_linear_schedule_with_warmup": ["<builtin>.max", "<builtin>.float", "torch.optim.lr_scheduler.LambdaLR"], "transformers.utils.versions.require_version": ["re.match", "re.findall", "<builtin>.ValueError", "<builtin>.list", "transformers.utils.versions._compare_versions", "<builtin>.str", "importlib.metadata.version", "importlib_metadata.version", "importlib.metadata.PackageNotFoundError", "importlib_metadata.PackageNotFoundError"], "transformers.modeling_utils.PreTrainedModel.__init__": ["<builtin>.super", "<builtin>.isinstance", "<builtin>.ValueError"], "transformers.models.distilbert.modeling_distilbert.Embeddings.__init__": ["<builtin>.super", "torch.nn.Embedding", "transformers.models.distilbert.modeling_distilbert.create_sinusoidal_embeddings", "torch.nn.LayerNorm", "torch.nn.Dropout", "packaging.version.parse", "torch.arange"], "transformers.models.distilbert.modeling_distilbert.Transformer.__init__": ["<builtin>.super", "torch.nn.ModuleList", "transformers.models.distilbert.modeling_distilbert.TransformerBlock.__init__", "<builtin>.range"], "transformers.modeling_utils.PreTrainedModel.post_init": ["transformers.modeling_utils.PreTrainedModel.init_weights", "transformers.modeling_utils.PreTrainedModel._backward_compatibility_gradient_checkpointing"], "transformers.file_utils.requires_backends": ["<builtin>.isinstance", "<builtin>.hasattr", "<builtin>.ImportError"], "transformers.models.albert.modeling_albert.AlbertEmbeddings.__init__": ["<builtin>.super", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.arange", "<builtin>.getattr", "packaging.version.parse", "torch.zeros"], "transformers.models.albert.modeling_albert.AlbertTransformer.__init__": ["<builtin>.super", "torch.nn.Linear", "torch.nn.ModuleList", "transformers.models.albert.modeling_albert.AlbertLayerGroup.__init__", "<builtin>.range"], "transformers.models.bert.modeling_bert.BertEmbeddings.__init__": ["<builtin>.super", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.Dropout", "<builtin>.getattr", "torch.arange", "packaging.version.parse", "torch.zeros"], "transformers.models.bert.modeling_bert.BertEncoder.__init__": ["<builtin>.super", "torch.nn.ModuleList", "transformers.models.bert.modeling_bert.BertLayer.__init__", "<builtin>.range"], "transformers.models.bert.modeling_bert.BertPooler.__init__": ["<builtin>.super", "torch.nn.Linear", "torch.nn.Tanh"], "transformers.utils.versions._compare_versions": ["<builtin>.ValueError", "<builtin>.ImportError", "packaging.version.parse"], "transformers.models.distilbert.modeling_distilbert.create_sinusoidal_embeddings": ["transformers.deepspeed.is_deepspeed_zero3_enabled", "transformers.models.distilbert.modeling_distilbert._create_sinusoidal_embeddings", "deepspeed.zero.GatheredParameters", "torch.distributed.get_rank"], "transformers.models.distilbert.modeling_distilbert.TransformerBlock.__init__": ["<builtin>.super", "transformers.models.distilbert.modeling_distilbert.MultiHeadSelfAttention.__init__", "torch.nn.LayerNorm", "transformers.models.distilbert.modeling_distilbert.FFN.__init__"], "transformers.modeling_utils.PreTrainedModel.init_weights": ["transformers.modeling_utils.PreTrainedModel.prune_heads", "transformers.modeling_utils.PreTrainedModel.tie_weights"], "transformers.modeling_utils.PreTrainedModel._backward_compatibility_gradient_checkpointing": ["<builtin>.getattr", "transformers.modeling_utils.PreTrainedModel.gradient_checkpointing_enable", "<builtin>.delattr"], "transformers.models.albert.modeling_albert.AlbertLayerGroup.__init__": ["<builtin>.super", "torch.nn.ModuleList", "transformers.models.albert.modeling_albert.AlbertLayer.__init__", "<builtin>.range"], "transformers.models.bert.modeling_bert.BertLayer.__init__": ["<builtin>.super", "transformers.models.bert.modeling_bert.BertAttention.__init__", "<builtin>.ValueError", "transformers.models.bert.modeling_bert.BertIntermediate.__init__", "transformers.models.bert.modeling_bert.BertOutput.__init__"], "transformers.models.distilbert.modeling_distilbert._create_sinusoidal_embeddings": ["numpy.array", "<builtin>.range", "numpy.power", "torch.FloatTensor", "numpy.sin", "numpy.cos"], "transformers.models.distilbert.modeling_distilbert.MultiHeadSelfAttention.__init__": ["<builtin>.super", "torch.nn.Dropout", "torch.nn.Linear", "<builtin>.set"], "transformers.models.distilbert.modeling_distilbert.FFN.__init__": ["<builtin>.super", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.ReLU"], "transformers.modeling_utils.PreTrainedModel.prune_heads": ["<builtin>.list", "<builtin>.set"], "transformers.modeling_utils.PreTrainedModel.tie_weights": ["transformers.modeling_utils.PreTrainedModel.get_output_embeddings", "<builtin>.getattr", "transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights", "transformers.modeling_utils.PreTrainedModel.get_input_embeddings", "<builtin>.hasattr", "transformers.modeling_utils.PreTrainedModel._tie_encoder_decoder_weights"], "transformers.modeling_utils.PreTrainedModel.gradient_checkpointing_enable": ["<builtin>.ValueError", "functools.partial"], "transformers.models.albert.modeling_albert.AlbertLayer.__init__": ["<builtin>.super", "torch.nn.LayerNorm", "transformers.models.albert.modeling_albert.AlbertAttention.__init__", "torch.nn.Linear", "torch.nn.Dropout"], "transformers.models.bert.modeling_bert.BertAttention.__init__": ["<builtin>.super", "transformers.models.bert.modeling_bert.BertSelfAttention.__init__", "transformers.models.bert.modeling_bert.BertSelfOutput.__init__", "<builtin>.set"], "transformers.models.bert.modeling_bert.BertIntermediate.__init__": ["<builtin>.super", "torch.nn.Linear", "<builtin>.isinstance"], "transformers.models.bert.modeling_bert.BertOutput.__init__": ["<builtin>.super", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.Dropout"], "transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights": ["torch.nn.Parameter", "<builtin>.getattr", "torch.nn.functional.pad", "<builtin>.hasattr"], "transformers.modeling_utils.PreTrainedModel.get_input_embeddings": ["<builtin>.getattr"], "transformers.modeling_utils.PreTrainedModel._tie_encoder_decoder_weights": ["<builtin>.hasattr", "<builtin>.isinstance", "<builtin>.len", "<builtin>.set", "<builtin>.list", "<builtin>.str", "<builtin>.int", "<builtin>.ValueError", "<builtin>.type"], "transformers.models.albert.modeling_albert.AlbertAttention.__init__": ["<builtin>.super", "<builtin>.ValueError", "<builtin>.hasattr", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.LayerNorm", "<builtin>.set", "<builtin>.getattr", "torch.nn.Embedding"], "transformers.models.bert.modeling_bert.BertSelfAttention.__init__": ["<builtin>.super", "<builtin>.ValueError", "<builtin>.hasattr", "<builtin>.int", "torch.nn.Linear", "torch.nn.Dropout", "<builtin>.getattr", "torch.nn.Embedding"], "transformers.models.bert.modeling_bert.BertSelfOutput.__init__": ["<builtin>.super", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.Dropout"]}